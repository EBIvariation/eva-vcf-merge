# Copyright 2014-2017 EMBL - European Bioinformatics Institute
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from pyspark import SparkConf, SparkContext
from pyspark.sql import SQLContext
import os, gzip, glob, traceback, subprocess, sys, SSMergeCommonUtils
from cassandra.cluster import Cluster

def insertDefaultGenotypeToCassandra(sampleName, defaultGenotype):
    """
    Insert default genotype, assumed for a given sample, into Cassandra.
    
    :param sampleName: Sample Name
    :type sampleName: str
    :param defaultGenotype: Default Genotype assumed for the sample
    :type defaultGenotype: str    
    """
    cassandraSession.execute(defaultGenotypeInsertPrepStmt.bind([sampleName, defaultGenotype]))

def getVariantInfo(matchLine):
    """
    Helper function to get variant information from the match file generated by this program 
    
    :param matchLine: A line from the match file generated by this program
    :type matchLine: str
    """
    chromMatch, varPosMatch, ref, alt, genotype, formatMatch, sampleinfoMatch = matchLine.strip().split("\t")
    varPosMatch = long(float(varPosMatch))
    chunk = int(varPosMatch / SSMergeCommonUtils.CHR_POS_CHUNKSIZE)
    return chromMatch, varPosMatch, ref, alt, genotype, formatMatch, sampleinfoMatch, chunk

def processVariantMatchFile(universalVarListFileName, matchOutputFileName, sampleName, defaultGenotype, missingGenotype):
    """
    Process a variant match file that is generated for every sample. The variant match file contains only entries 
    at the variant positions (determined from the first pass. see SingleSampleMerge.py) for a given sample .
    
    :param universalVarListFileName: Full path to the file which contains the complete set of unique variant positions
                                        across all samples (determined from the first pass. see SingleSampleMerge.py)
    :type universalVarListFileName: str
    :param matchOutputFileName: Full path to the VCF file for a given sample which only has variant positions  
                                    matched against the unique variant positions obtained from across all samples
    :type matchOutputFileName: str
    :param sampleName: Sample Name
    :type sampleName: str
    :param defaultGenotype: Default genotype assumed for the sample
    :type defaultGenotype: str
    :param missingGenotype: Default genotype assumed for the sample
    :type missingGenotype: str
    """
    # Insert default genotype assumed for the sample into Cassandra
    insertDefaultGenotypeToCassandra(sampleName, defaultGenotype)

    # Compare the universal variant list against the matches found at variant positions in the individual sample files
    with gzip.open(universalVarListFileName, "rb") as varListFile:
        with gzip.open(matchOutputFileName, "rb") as varMatchFile:
            for matchLine in varMatchFile:
                chromMatch, varPosMatch, ref, alt, genotype, \
                formatMatch, sampleinfoMatch, chunk = getVariantInfo(matchLine)
                for varPosLine in varListFile:
                    varPosLine = varPosLine.strip()
                    chromToFind, varPosToFind  = varPosLine.split("\t")
                    varPosToFind = long(float(varPosToFind))

                    # region Handle an edge case THAT SHOULD NOT HAPPEN
                    # If a variant position from the universal variant list is farther than
                    # the position in the match file. This can happen if the match file has multiple entries for
                    # the same position. In such cases, forward to a position in the match file
                    while varPosToFind > varPosMatch:
                        matchLine = varMatchFile.readline()
                        if not matchLine: return
                        chromMatch, varPosMatch, ref, alt, genotype, \
                        formatMatch, sampleinfoMatch, chunk = getVariantInfo(matchLine)
                    # endregion

                    # If we assumed the default was a "missing" genotype (ex: ./.) for a sample, insert to Cassandra
                    # if we have evidence otherwise i.e.,a match was found at a variant position in the sample.
                    #
                    # If we assumed the default was a "non-missing" genotype (ex: 0/0) for a sample, insert to Cassandra
                    # if we have evidence otherwise i.e.,no variant was found at a position in the sample (or)
                    # the variant found at the position had a different genotype than the default genotype (ex: 0/1)
                    if (chromToFind, varPosToFind) == (chromMatch, varPosMatch):
                        if genotype == defaultGenotype or alt != '.': break
                        cassandraSession.execute(variantInsertPrepStmt.bind(
                                [chromToFind, chunk, varPosToFind, ref, alt, sampleName, formatMatch, sampleinfoMatch]))
                        break
                    else:
                        if defaultGenotype != "./." and defaultGenotype != ".|.":
                            cassandraSession.execute(variantInsertPrepStmt.bind(
                                [chromToFind, chunk, varPosToFind, ref, alt, sampleName, "GT", missingGenotype]))


def getNumMatchedVariants(keyspaceName, sampleInsertLogTableName, studyName, sampleName):
    """
    Get number of matched variant positions in a given sample when matched 
    against the universal set of variant positions from the first pass (see SingleSampleMerge.py)  
    
    :param keyspaceName: Cassandra keyspace
    :type keyspaceName: str
    :param sampleInsertLogTableName: Cassandra Sample Insert log table name
    :type sampleInsertLogTableName: str
    :param studyName: Study Name (ex: PRJEB21300)
    :type studyName: str
    :param sampleName: Sample Name
    :type sampleName: str
    :return: Number of variant positions matched for the given sample
    :rtype: int
    """
    rows = cassandraSession.execute ("select num_variants from {0}.{1} where studyname = '{2}' and samplename = '{3}'".format(keyspaceName, sampleInsertLogTableName, studyName, sampleName))
    if rows:
        rows = iter(rows)
        return rows.next().num_variants
    else:
        raise Exception("Could not find number of matched variants for the sample: {0}".format(sampleName))


def matchVariantPosInStudyFiles(bcfToolsDir, studyName, studyFileName, studyFilesInputDir, variantPositionFileName,
                                numTotVariants, defaultGenotype, missingGenotype, cassandraNodeIPs, keyspaceName,
                                sampleDefaultsTableName, variantTableName, sampleInsertLogTableName):
    """
    Match the universal set of unique variant positions from across all samples 
    (obtained from first pass, see SingleSampleMerge.py)
    
    :param bcfToolsDir: Directory containing the bcftools static binaries
    :type bcfToolsDir: str
    :param studyName: Study Name
    :type studyName: str
    :param studyFileName: File Name for the specific sample being matched for variant positions
    :type studyFileName: str
    :param studyFilesInputDir: Input directory where the single sample files reside
    :type studyFilesInputDir: str
    :param variantPositionFileName: Full path to file that has all the unique variant positions obtained form first pass
    :type variantPositionFileName: str
    :param numTotVariants: Total number of variants that were inserted into Cassandra during the first pass
    :type numTotVariants: long
    :param defaultGenotype: Default genotype to use for the sample
    :type defaultGenotype: str
    :param missingGenotype: Missing genotype to use for the sample
    :type missingGenotype: str
    :param cassandraNodeIPs: Set of IP addresses to connect to the Cassandra cluster
    :type cassandraNodeIPs: list[str]
    :param keyspaceName: Cassandra key space where the variant table resides
    :type keyspaceName: str
    :param sampleDefaultsTableName: Name of the Cassandra table that has the default genotypes per sample
    :type sampleDefaultsTableName: str
    :param variantTableName: Cassandra variant table
    :type variantTableName: str
    :param sampleInsertLogTableName: Cassandra sample insert log table to determine the number of variants in the sample
    :type sampleInsertLogTableName: str
    :return: Error messages, if any, during the function execution. None otherwise.
    :rtype: str
    """
    global cassandraCluster, cassandraSession, defaultGenotypeInsertPrepStmt, variantInsertPrepStmt
    cassandraCluster = Cluster(cassandraNodeIPs)
    cassandraSession = cassandraCluster.connect(keyspaceName)
    defaultGenotypeInsertPrepStmt = cassandraSession.prepare("insert into {0}.{1} (samplename, default_genotype) values (?,?)".format(keyspaceName, sampleDefaultsTableName))
    variantInsertPrepStmt = cassandraSession.prepare("insert into {0}.{1} (chrom,chunk,start_pos,ref,alt,samplename, sampleinfoformat, sampleinfo) values (?,?,?,?,?,?,?,?)".format(keyspaceName, variantTableName))

    returnErrMsg = None
    chosenFileToProcess = studyFileName
    try:
        baseDir = studyFilesInputDir
        os.chdir(baseDir)
        sampleNameCmd = subprocess.Popen("{0}/bin/bcftools query -l {1}".format(bcfToolsDir, chosenFileToProcess),
                                         shell=True, stdout=subprocess.PIPE)
        sampleName, err = sampleNameCmd.communicate()
        if err: return "Could not obtain sample name from the SNP file:{0}".format(chosenFileToProcess)
        sampleName = sampleName.strip()

        matchOutputFileName = sampleName + "_variantmatch.gz"
        errFileName = sampleName + "_variantmatch.err"
        bcfVariantMatchCmd = "({0}/bin/bcftools query -f'%CHROM\\t%POS\\t%REF\\t%ALT[\\t%GT]\\t%LINE' -T {1} {3} | cut -f1,2,3,4,5,14,15 | gzip) 1> {2} 2> {4}".format(bcfToolsDir, variantPositionFileName, matchOutputFileName, chosenFileToProcess, errFileName)

        os.system(bcfVariantMatchCmd)
        errFileHandle = open(errFileName, "r")
        errlines = errFileHandle.readlines()
        errFileHandle.close()
        if not errlines:
            numMatchedVariants = getNumMatchedVariants(keyspaceName, sampleInsertLogTableName, studyName, sampleName)
            if (numTotVariants*1.0/numMatchedVariants) > 2:
                processVariantMatchFile(variantPositionFileName, matchOutputFileName, sampleName, missingGenotype,missingGenotype)
            else:
                processVariantMatchFile(variantPositionFileName, matchOutputFileName, sampleName, defaultGenotype, missingGenotype)
        else:
            returnErrMsg = "Error in processing file:{0}".format(chosenFileToProcess) + os.linesep + os.linesep.join(errlines)
    except Exception, e:
        returnErrMsg = "Error in processing file:{0}".format(chosenFileToProcess) + os.linesep + traceback.format_exc()
    finally:
        cassandraCluster.shutdown()
        cassandraSession.shutdown()
        if returnErrMsg: return returnErrMsg
        return None

if __name__ == "__main__":

    if len(sys.argv) != 8:
        print("Usage: ProcessVariantMatches.py <Study PRJ ID> <Default Genotype> <Missing Genotype> <Full Path to study files> <Cassandra node IP1> <Cassandra node IP2> <BCF Tools Directory>")
        sys.exit(1)

    # region Parse arguments
    studyName = sys.argv[1]
    defaultGenotype = sys.argv[2]
    missingGenotype = sys.argv[3]
    studyFilesInputDir = sys.argv[4]
    cassandraNodeIPs = [sys.argv[5], sys.argv[6]]
    bcfToolsDir = sys.argv[7]
    # endregion

    # region Get the list of study files
    os.chdir(studyFilesInputDir)
    dirContents = glob.glob("*_filtervcf.gz")
    dirContents.sort()
    studyFileNames = dirContents
    # endregion

    # region Initialize variant, header, sample insert log and study table names in Cassandra
    keyspaceName = "variant_ksp"
    variantTableName = "variants_{0}".format(studyName.lower())
    sampleInsertLogTableName = "sample_insert_log"
    sampleDefaultsTableName = "sample_defaults_{0}".format(studyName.lower())
    studyInfoTableName = "study_info_{0}".format(studyName.lower())
    uniquePosTableName = "uniq_pos_{0}".format(studyName.lower())
    local_cluster_var = Cluster(cassandraNodeIPs)
    local_session_var = local_cluster_var.connect()
    local_session_var.execute("create table if not exists {0}.{1} (samplename varchar, default_genotype varchar, primary key(samplename));"
                              .format(keyspaceName,sampleDefaultsTableName))
    # endregion

    # region Initialize Apache Spark
    conf = SparkConf().setMaster("spark://{0}:7077".format(SSMergeCommonUtils.get_ip_address())).setAppName("SingleSampleVCFMerge").set("spark.cassandra.connection.host", cassandraNodeIPs[0]).set("spark.scheduler.listenerbus.eventqueue.size", "100000").set("spark.cassandra.read.timeout_ms", 1200000).set("spark.cassandra.connection.timeout_ms", 1200000)
    sc = SparkContext(conf=conf)
    sc.setLogLevel("INFO")
    # endregion

    # region Obtain the total number of variants from across the samples as determined from the first pass
    variantPositionFileName = studyFilesInputDir + os.path.sep + "unique_variant_positions.gz"
    rows = local_session_var.execute("select tot_num_variants from {0}.{1};".format(keyspaceName, studyInfoTableName))
    numTotVariants = 0
    if rows:
        rows = iter(rows)
        numTotVariants = rows.next().tot_num_variants
    else:
        raise Exception("Could not obtain number of variants for the study: {0} from the table: {1}.{2}"
                        .format(studyName, keyspaceName, studyInfoTableName))
    # endregion

    # region Generate a position file with the unique set of variant positions determined from the first pass
    sql = SQLContext(sc)
    variants = sql.read.format("org.apache.spark.sql.cassandra").\
                   load(keyspace=keyspaceName, table=uniquePosTableName)
    variants.registerTempTable("variantsTable")
    resultDF = sql.sql("select chrom,start_pos from variantsTable order by 1,2")
    iterator = resultDF.toLocalIterator()

    variantPositionFileHandle = gzip.open(variantPositionFileName, "wb")
    for result in iterator:
        discardOutput = variantPositionFileHandle.write(result["chrom"] + "\t" + str(result["start_pos"]) + os.linesep)
    variantPositionFileHandle.close()
    # endregion

    # region Scan each sample file against the unique set of variant positions
    # to insert sample genotypes at these positions
    numPartitions = len(studyFileNames)
    studyIndivRDD = sc.parallelize(studyFileNames, numPartitions)
    processResults = studyIndivRDD.map(lambda studyFileName: matchVariantPosInStudyFiles(bcfToolsDir, studyName,
                                                                                         studyFileName, studyFilesInputDir,
                                                                                         variantPositionFileName,
                                                                                         numTotVariants, defaultGenotype,
                                                                                         missingGenotype, cassandraNodeIPs,
                                                                                         keyspaceName,
                                                                                         sampleDefaultsTableName,
                                                                                         variantTableName,
                                                                                         sampleInsertLogTableName)).collect()
    # endregion

    # region Print any error messages obtained from the process above
    for result in processResults:
        if result:
            print(result)
    # endregion

    # region Shutdown Cassandra and Apache Spark
    local_session_var.shutdown()
    local_cluster_var.shutdown()
    sc.stop()
    # endregion